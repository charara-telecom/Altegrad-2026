{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7jEuScJ9fPx"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip -q install -U sacrebleu transformers scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N6rkM4a86la",
        "outputId": "b0fa4534-ea1d-421c-a232-57a8a5a3c771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b8b2cd3f0c1a4329b2d76b88c2e5bfc0",
            "4dd8115b782745cc95a149ab9b33e57d",
            "c4aba02db5de43d3a98e7e602b107d5a",
            "45fdc78a3ef243a79f23ba8887daf092",
            "eed8a8ae65604eb3bde5b1e973f4474e",
            "e35513690b674c6e9a076b1921f374cb",
            "f734b85eb5a04a03af1d5b5d643cbd99",
            "2f60acb947204b1abe43e3cf15ad585a",
            "f181094afd1e4b90afce285a094242d4",
            "c5e0db96fe7f40db8b0ff9f9efc0316d",
            "97a495d223f946ff8230cc97a84df861",
            "ef4dd97d46224613a348ebb812f25b49",
            "012abfe890ab47e28148f78bc9bfbe8b",
            "ddf74fc6b5e341bdb7e910e57d33f6ef",
            "21c34265184a4677936125e8831a9348",
            "fee3ab68a6b9451b9327745c701f69b3",
            "5d784dd987d940adbbb7ca32181e145d",
            "ea3a6d849cb24ebb88b852ca97bfbab3",
            "34ef261d493b44d8b0c33fb9ace2b651",
            "5d35dc7ec5834548be157f8a56133c3f",
            "a348fd4d5455405eba966d551b30c6bb",
            "991af4b385474cee845d49dd86a9b6d4",
            "509bf928bc424bb2894c49630bf0dbc2"
          ]
        },
        "id": "xprDvxwQH96y",
        "outputId": "422dfa15-a583-41b1-ca0d-38281210b8db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8b2cd3f0c1a4329b2d76b88c2e5bfc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle credentials set.\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "source": [
        "# Load dataset (KaggleHub)\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUP_yPLe-ttw",
        "outputId": "71fd6906-5b11-4881-9ce8-bb05b3e599e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "comp_path: /root/.cache/kagglehub/competitions/molecular-graph-captioning\n",
            "Loaded: 31008 1000 1000\n",
            "Fields present: ['x', 'edge_index', 'edge_attr', 'description', 'id']\n",
            "x: torch.Size([40, 9]) edge_attr: torch.Size([86, 3]) edge_index: torch.Size([2, 86])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os, sys, pickle\n",
        "\n",
        "comp_path = kagglehub.competition_download(\"molecular-graph-captioning\")\n",
        "print(\"comp_path:\", comp_path)\n",
        "\n",
        "BASELINE_DIR = os.path.join(comp_path, \"data_baseline\")\n",
        "DATA_DIR     = os.path.join(BASELINE_DIR, \"data\")\n",
        "\n",
        "sys.path.append(BASELINE_DIR)\n",
        "from data_utils import x_map, e_map\n",
        "\n",
        "TRAIN_PKL = os.path.join(DATA_DIR, \"train_graphs.pkl\")\n",
        "VAL_PKL   = os.path.join(DATA_DIR, \"validation_graphs.pkl\")\n",
        "TEST_PKL  = os.path.join(DATA_DIR, \"test_graphs.pkl\")\n",
        "\n",
        "def load_pkl(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "train_graphs = load_pkl(TRAIN_PKL)\n",
        "val_graphs   = load_pkl(VAL_PKL)\n",
        "test_graphs  = load_pkl(TEST_PKL)\n",
        "\n",
        "print(\"Loaded:\", len(train_graphs), len(val_graphs), len(test_graphs))\n",
        "print(\"Fields present:\", [k for k in [\"x\",\"edge_index\",\"edge_attr\",\"smiles\",\"description\",\"id\",\"idx\"] if hasattr(train_graphs[0], k)])\n",
        "print(\"x:\", train_graphs[0].x.shape, \"edge_attr:\", train_graphs[0].edge_attr.shape, \"edge_index:\", train_graphs[0].edge_index.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNSXG-Ca---I",
        "outputId": "20ae7474-078d-4795-93ff-a34d857f2695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOW_DIM: 207\n",
            "Building BOW vectors...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31008/31008 [00:08<00:00, 3850.20it/s] \n",
            "100%|██████████| 1000/1000 [00:00<00:00, 10753.33it/s]\n",
            "100%|██████████| 1000/1000 [00:00<00:00, 8546.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (31008, 207) (1000, 207) (1000, 207)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Build BOW vectors\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "x_feature_names = list(x_map.keys())\n",
        "e_feature_names = list(e_map.keys())\n",
        "\n",
        "x_sizes = [len(x_map[k]) for k in x_feature_names]\n",
        "e_sizes = [len(e_map[k]) for k in e_feature_names]\n",
        "BOW_DIM = sum(x_sizes) + sum(e_sizes)\n",
        "print(\"BOW_DIM:\", BOW_DIM)\n",
        "\n",
        "def graph_to_bow(g):\n",
        "    x = g.x.detach().cpu().numpy().astype(np.int64)\n",
        "    e = None\n",
        "    if hasattr(g, \"edge_attr\") and g.edge_attr is not None and g.edge_attr.numel() > 0:\n",
        "        e = g.edge_attr.detach().cpu().numpy().astype(np.int64)\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    # node histograms\n",
        "    for j, sz in enumerate(x_sizes):\n",
        "        col = x[:, j] if j < x.shape[1] else np.zeros((x.shape[0],), dtype=np.int64)\n",
        "        col = np.clip(col, 0, sz - 1)\n",
        "        parts.append(np.bincount(col, minlength=sz).astype(np.float32))\n",
        "\n",
        "    # edge histograms\n",
        "    if e is None:\n",
        "        for sz in e_sizes:\n",
        "            parts.append(np.zeros((sz,), dtype=np.float32))\n",
        "    else:\n",
        "        for j, sz in enumerate(e_sizes):\n",
        "            col = e[:, j] if j < e.shape[1] else np.zeros((e.shape[0],), dtype=np.int64)\n",
        "            col = np.clip(col, 0, sz - 1)\n",
        "            parts.append(np.bincount(col, minlength=sz).astype(np.float32))\n",
        "\n",
        "    v = np.concatenate(parts, axis=0)\n",
        "    v = v / (np.linalg.norm(v) + 1e-12)\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "print(\"Building BOW vectors...\")\n",
        "B_train = np.stack([graph_to_bow(g) for g in tqdm(train_graphs)], axis=0)\n",
        "B_val   = np.stack([graph_to_bow(g) for g in tqdm(val_graphs)], axis=0)\n",
        "B_test  = np.stack([graph_to_bow(g) for g in tqdm(test_graphs)], axis=0)\n",
        "\n",
        "print(\"Shapes:\", B_train.shape, B_val.shape, B_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n07lD8zSHeZn",
        "outputId": "441a9058-1c2a-41a8-a878-2bd9ee2e976e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOW_DIM: 207\n",
            "Building BOW vectors...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31008/31008 [00:02<00:00, 11048.57it/s]\n",
            "100%|██████████| 1000/1000 [00:00<00:00, 10302.78it/s]\n",
            "100%|██████████| 1000/1000 [00:00<00:00, 9272.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (31008, 207) (1000, 207) (1000, 207)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Build BOW vectors (alternate)\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "x_feature_names = list(x_map.keys())\n",
        "e_feature_names = list(e_map.keys())\n",
        "\n",
        "x_sizes = [len(x_map[k]) for k in x_feature_names]\n",
        "e_sizes = [len(e_map[k]) for k in e_feature_names]\n",
        "BOW_DIM = sum(x_sizes) + sum(e_sizes)\n",
        "print(\"BOW_DIM:\", BOW_DIM)\n",
        "\n",
        "def graph_to_bow(g):\n",
        "    x = g.x.detach().cpu().numpy().astype(np.int64)\n",
        "    e = None\n",
        "    if hasattr(g, \"edge_attr\") and g.edge_attr is not None and g.edge_attr.numel() > 0:\n",
        "        e = g.edge_attr.detach().cpu().numpy().astype(np.int64)\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    # node histograms\n",
        "    for j, sz in enumerate(x_sizes):\n",
        "        col = x[:, j] if j < x.shape[1] else np.zeros((x.shape[0],), dtype=np.int64)\n",
        "        col = np.clip(col, 0, sz - 1)\n",
        "        parts.append(np.bincount(col, minlength=sz).astype(np.float32))\n",
        "\n",
        "    # edge histograms\n",
        "    if e is None:\n",
        "        for sz in e_sizes:\n",
        "            parts.append(np.zeros((sz,), dtype=np.float32))\n",
        "    else:\n",
        "        for j, sz in enumerate(e_sizes):\n",
        "            col = e[:, j] if j < e.shape[1] else np.zeros((e.shape[0],), dtype=np.int64)\n",
        "            col = np.clip(col, 0, sz - 1)\n",
        "            parts.append(np.bincount(col, minlength=sz).astype(np.float32))\n",
        "\n",
        "    v = np.concatenate(parts, axis=0)\n",
        "    v = v / (np.linalg.norm(v) + 1e-12)\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "print(\"Building BOW vectors...\")\n",
        "B_train = np.stack([graph_to_bow(g) for g in tqdm(train_graphs)], axis=0)\n",
        "B_val   = np.stack([graph_to_bow(g) for g in tqdm(val_graphs)], axis=0)\n",
        "B_test  = np.stack([graph_to_bow(g) for g in tqdm(test_graphs)], axis=0)\n",
        "\n",
        "print(\"Shapes:\", B_train.shape, B_val.shape, B_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orgEC6hSJyGX",
        "outputId": "036040c6-cb68-4031-afaf-4787b2f61b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n",
            "x_vocabs: [86, 3, 7, 10, 5, 5, 7, 2, 2]\n",
            "e_vocabs: [13, 4, 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Retriever epoch 1/3: 100%|██████████| 243/243 [01:48<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 | loss 2.1504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retriever epoch 2/3: 100%|██████████| 243/243 [01:49<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 | loss 0.8115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retriever epoch 3/3: 100%|██████████| 243/243 [01:52<00:00,  2.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 | loss 0.5043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embed GNN: 100%|██████████| 122/122 [00:02<00:00, 49.44it/s]\n",
            "Embed GNN: 100%|██████████| 4/4 [00:00<00:00, 48.21it/s]\n",
            "Embed GNN: 100%|██████████| 4/4 [00:00<00:00, 46.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Z shapes: (31008, 256) (1000, 256) (1000, 256)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train dual retriever (GNN + text)\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "# Repro\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# (Optional) keep installs in a separate setup cell on Kaggle\n",
        "# !pip -q install -U torch-geometric pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-$(python -c \"import torch;print(torch.__version__.split('+')[0])\")+cu$(python -c \"import torch;print(torch.version.cuda.replace('.',''))\").html\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.nn import GINEConv, global_mean_pool\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Infer vocab sizes for categorical embeddings\n",
        "def infer_vocabs_all(graphs):\n",
        "    # graphs: list of PyG Data objects\n",
        "    x_max = None\n",
        "    e_max = None\n",
        "\n",
        "    for g in graphs:\n",
        "        x = g.x\n",
        "        if x_max is None:\n",
        "            x_max = x.max(dim=0).values\n",
        "        else:\n",
        "            x_max = torch.maximum(x_max, x.max(dim=0).values)\n",
        "\n",
        "        ea = getattr(g, \"edge_attr\", None)\n",
        "        if ea is not None and ea.numel() > 0:\n",
        "            if e_max is None:\n",
        "                e_max = ea.max(dim=0).values\n",
        "            else:\n",
        "                e_max = torch.maximum(e_max, ea.max(dim=0).values)\n",
        "\n",
        "    if e_max is None:\n",
        "        e_max = torch.zeros(3, dtype=torch.long)\n",
        "\n",
        "    x_vocabs = (x_max + 1).tolist()\n",
        "    e_vocabs = (e_max + 1).tolist()\n",
        "    return [int(v) for v in x_vocabs], [int(v) for v in e_vocabs]\n",
        "\n",
        "x_vocabs, e_vocabs = infer_vocabs_all(train_graphs)   # or train_graphs + val_graphs\n",
        "print(\"x_vocabs:\", x_vocabs)\n",
        "print(\"e_vocabs:\", e_vocabs)\n",
        "\n",
        "\n",
        "# Categorical feature embedders\n",
        "class CatFeatureEmbedder(nn.Module):\n",
        "    def __init__(self, vocabs, emb_dim):\n",
        "        super().__init__()\n",
        "        self.embs = nn.ModuleList([nn.Embedding(v, emb_dim) for v in vocabs])\n",
        "\n",
        "    def forward(self, x_int):  # [N, F] int\n",
        "        # sum embeddings across feature fields\n",
        "        out = 0\n",
        "        for j, emb in enumerate(self.embs):\n",
        "            out = out + emb(x_int[:, j])\n",
        "        return out\n",
        "\n",
        "# GNN encoder\n",
        "class GNNEncoder(nn.Module):\n",
        "    def __init__(self, x_vocabs, e_vocabs, hidden=256, out_dim=256, layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.node_emb = CatFeatureEmbedder(x_vocabs, hidden)\n",
        "        self.edge_emb = CatFeatureEmbedder(e_vocabs, hidden)\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.norms = nn.ModuleList()\n",
        "        for _ in range(layers):\n",
        "            mlp = nn.Sequential(\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, hidden),\n",
        "            )\n",
        "            self.convs.append(GINEConv(mlp, edge_dim=hidden))\n",
        "            self.norms.append(nn.LayerNorm(hidden))\n",
        "\n",
        "        self.out = nn.Linear(hidden, out_dim)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # batch.x and batch.edge_attr are categorical indices\n",
        "        x = self.node_emb(batch.x.long())\n",
        "\n",
        "        e = None\n",
        "        if batch.edge_attr is not None and batch.edge_attr.numel() > 0:\n",
        "            e = self.edge_emb(batch.edge_attr.long())\n",
        "\n",
        "        for conv, ln in zip(self.convs, self.norms):\n",
        "            x = conv(x, batch.edge_index, e) if e is not None else conv(x, batch.edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = ln(x)  # stability\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        g = global_mean_pool(x, batch.batch)\n",
        "        g = self.out(g)\n",
        "        return F.normalize(g, dim=-1)\n",
        "\n",
        "# Text encoder\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, name=\"sentence-transformers/all-MiniLM-L6-v2\", out_dim=256):\n",
        "        super().__init__()\n",
        "        self.tok = AutoTokenizer.from_pretrained(name)\n",
        "        self.enc = AutoModel.from_pretrained(name)\n",
        "        self.proj = nn.Linear(self.enc.config.hidden_size, out_dim)\n",
        "\n",
        "    def forward(self, texts):\n",
        "        batch = self.tok(\n",
        "            texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\"\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        out = self.enc(**batch)\n",
        "        attn = batch[\"attention_mask\"].unsqueeze(-1)\n",
        "        pooled = (out.last_hidden_state * attn).sum(1) / (attn.sum(1) + 1e-12)\n",
        "\n",
        "        z = self.proj(pooled)\n",
        "        return F.normalize(z, dim=-1)\n",
        "\n",
        "class DualRetriever(nn.Module):\n",
        "    def __init__(self, x_vocabs, e_vocabs, dim=256, gnn_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.gnn = GNNEncoder(x_vocabs, e_vocabs, hidden=256, out_dim=dim, layers=gnn_layers, dropout=dropout)\n",
        "        self.txt = TextEncoder(\"sentence-transformers/all-MiniLM-L6-v2\", out_dim=dim)\n",
        "\n",
        "def info_nce(mol_z, txt_z, temp=0.07):\n",
        "    logits = mol_z @ txt_z.t() / temp\n",
        "    labels = torch.arange(logits.size(0), device=logits.device)\n",
        "    return (F.cross_entropy(logits, labels) + F.cross_entropy(logits.t(), labels)) / 2\n",
        "\n",
        "# Dataset and dataloader\n",
        "class RetrieverDS(Dataset):\n",
        "    def __init__(self, graphs):\n",
        "        self.graphs = graphs\n",
        "    def __len__(self): return len(self.graphs)\n",
        "    def __getitem__(self, i):\n",
        "        g = self.graphs[i]\n",
        "        txt = getattr(g, \"description\", \"\")\n",
        "        return g, str(txt) if txt is not None else \"\"\n",
        "\n",
        "def collate_retr(batch):\n",
        "    graphs, texts = zip(*batch)\n",
        "    pyg = Batch.from_data_list(list(graphs))\n",
        "    return pyg, list(texts)\n",
        "\n",
        "# Training setup\n",
        "DIM = 256          # try 128 vs 256 if you want\n",
        "GNN_LAYERS = 4     # recommended sweep: 3,4,5\n",
        "DROPOUT = 0.1\n",
        "BATCH = 128 if DEVICE == \"cuda\" else 64  # bigger batch = better contrastive negatives\n",
        "\n",
        "retr = DualRetriever(x_vocabs, e_vocabs, dim=DIM, gnn_layers=GNN_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
        "opt  = torch.optim.AdamW(retr.parameters(), lr=2e-4, weight_decay=1e-2)\n",
        "\n",
        "loader = DataLoader(\n",
        "    RetrieverDS(train_graphs),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=collate_retr\n",
        ")\n",
        "\n",
        "EPOCHS = 3  # recommended 1–3; often 2 is sweet spot\n",
        "retr.train()\n",
        "for ep in range(EPOCHS):\n",
        "    losses = []\n",
        "    for pyg, texts in tqdm(loader, desc=f\"Retriever epoch {ep+1}/{EPOCHS}\"):\n",
        "        pyg = pyg.to(DEVICE)\n",
        "\n",
        "        mol_z = retr.gnn(pyg)\n",
        "        txt_z = retr.txt(texts)\n",
        "        loss = info_nce(mol_z, txt_z, temp=0.07)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(retr.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "    print(f\"epoch {ep+1} | loss {float(np.mean(losses)):.4f}\")\n",
        "\n",
        "# Embed graphs using trained GNN\n",
        "@torch.no_grad()\n",
        "def embed_gnn(graphs, bs=256):\n",
        "    retr.eval()\n",
        "    out = []\n",
        "    for i in tqdm(range(0, len(graphs), bs), desc=\"Embed GNN\"):\n",
        "        pyg = Batch.from_data_list(graphs[i:i+bs]).to(DEVICE)\n",
        "        z = retr.gnn(pyg).detach().cpu().numpy().astype(np.float32)\n",
        "        out.append(z)\n",
        "    return np.vstack(out)\n",
        "\n",
        "Z_train = embed_gnn(train_graphs)\n",
        "Z_val   = embed_gnn(val_graphs)\n",
        "Z_test  = embed_gnn(test_graphs)\n",
        "\n",
        "print(\"Z shapes:\", Z_train.shape, Z_val.shape, Z_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ds2uGncXPjMb"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U bert-score transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "7YxF0M2B_FNI",
        "outputId": "9b40bb11-cda3-43ff-9aa8-60a307c4092c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERTScore DEVICE: cuda\n",
            "have_gnn: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieve topk=64 alpha=0.8: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.02 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.02 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.02 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.03 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.03 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.03 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.05 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.05 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.5 gap_min=0.05 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.02 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.02 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.02 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.03 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.03 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.03 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.05 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.05 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.55 gap_min=0.05 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.02 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.02 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.02 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.03 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.03 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.03 beta=14.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.05 beta=6.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.05 beta=10.0\n",
            "VAL comp=0.7318 | BLEU=48.668 | ChemBERTa-F1=0.9768 | top1_min=0.6 gap_min=0.05 beta=14.0\n",
            "BEST: (0.7317558034421854, {'top1_min': 0.5, 'gap_min': 0.02, 'beta': 6.0, 'bleu': 48.668338937796214, 'bert_f1': 0.9768282175064087})\n",
            "Using: top1_min=0.5, gap_min=0.02, beta=6.0 (BLEU=48.668, BERT=0.9768)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieve topk=64 alpha=0.8: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
            "Predict test: 100%|██████████| 1000/1000 [00:00<00:00, 437362.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example preds: [\"The molecule is a beta-D-glucosyl-(1<->1')-N-acylsphinganine in which the acyl group specified is hexacosanoyl. It has a role as a mouse metabolite. It derives from a hexacosanoic acid.\", 'The molecule is the monohydrate form of doxapram hydrochloride. A central and respiratory stimulant with a brief duration of action, it is used as a temporary treatment of acute respiratory failure, particularly when superimposed on chronic obstructive pulmonary disease, and of postoperative respiratory depression. It has also been used for treatment of postoperative shivering. It has a role as a central nervous system stimulant. It contains a doxapram hydrochloride (anhydrous).', 'The molecule is a steroid glucosiduronic acid having etiocholanolone as the steroid component. It has a role as a human blood serum metabolite, a human urinary metabolite, a human xenobiotic metabolite and a marine xenobiotic metabolite. It is a steroid glucosiduronic acid and a 17-oxo steroid. It is a conjugate acid of an etiocholanolone 3-glucuronide(1-).']\n",
            "✅ Wrote submission.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(sub\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1\",\n          \"4\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The molecule is the monohydrate form of doxapram hydrochloride. A central and respiratory stimulant with a brief duration of action, it is used as a temporary treatment of acute respiratory failure, particularly when superimposed on chronic obstructive pulmonary disease, and of postoperative respiratory depression. It has also been used for treatment of postoperative shivering. It has a role as a central nervous system stimulant. It contains a doxapram hydrochloride (anhydrous).\",\n          \"The molecule is an organochlorine compound that consists of acetaldehyde where all the methyl hydrogens are replaced by chloro groups. It has a role as a mouse metabolite. It is an organochlorine compound and an aldehyde. It derives from an acetaldehyde.\",\n          \"The molecule is a steroid glucosiduronic acid having etiocholanolone as the steroid component. It has a role as a human blood serum metabolite, a human urinary metabolite, a human xenobiotic metabolite and a marine xenobiotic metabolite. It is a steroid glucosiduronic acid and a 17-oxo steroid. It is a conjugate acid of an etiocholanolone 3-glucuronide(1-).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-198bd094-1fc5-4ad9-a60b-22dc66b6c39b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The molecule is a beta-D-glucosyl-(1&lt;-&gt;1')-N-a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The molecule is the monohydrate form of doxapr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>The molecule is a steroid glucosiduronic acid ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The molecule is a hydroxy fatty acid ascarosid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The molecule is an organochlorine compound tha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-198bd094-1fc5-4ad9-a60b-22dc66b6c39b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-198bd094-1fc5-4ad9-a60b-22dc66b6c39b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-198bd094-1fc5-4ad9-a60b-22dc66b6c39b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  id                                        description\n",
              "0  0  The molecule is a beta-D-glucosyl-(1<->1')-N-a...\n",
              "1  1  The molecule is the monohydrate form of doxapr...\n",
              "2  2  The molecule is a steroid glucosiduronic acid ...\n",
              "3  3  The molecule is a hydroxy fatty acid ascarosid...\n",
              "4  4  The molecule is an organochlorine compound tha..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sacrebleu\n",
        "import torch\n",
        "from bert_score import score as bertscore\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"BERTScore DEVICE:\", DEVICE)\n",
        "\n",
        "def chemberta_bertscore_f1(preds, refs, batch_size=32, max_length=128):\n",
        "    \"\"\"\n",
        "    BERTScore F1 using ChemBERTa-zinc-base-v1 with your bert-score version.\n",
        "    Key trick: pass num_layers explicitly to avoid KeyError.\n",
        "    \"\"\"\n",
        "    P, R, F1 = bertscore(\n",
        "        preds, refs,\n",
        "        lang=\"en\",\n",
        "        model_type=\"seyonec/ChemBERTa-zinc-base-v1\",\n",
        "        num_layers=6,                 # <-- base model: 6 transformer layers\n",
        "        device=DEVICE,\n",
        "        batch_size=batch_size,\n",
        "        verbose=False,\n",
        "        rescale_with_baseline=False,\n",
        "        use_fast_tokenizer=True\n",
        "    )\n",
        "    return float(F1.mean().cpu())\n",
        "\n",
        "def eval_bleu_chembertscore(preds, refs, sample_size=2000, seed=42):\n",
        "    assert len(preds) == len(refs)\n",
        "\n",
        "    if sample_size is not None and sample_size < len(preds):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        idx = rng.choice(len(preds), size=sample_size, replace=False)\n",
        "        preds_s = [preds[i] for i in idx]\n",
        "        refs_s  = [refs[i] for i in idx]\n",
        "    else:\n",
        "        preds_s, refs_s = preds, refs\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(preds_s, [refs_s]).score  # 0..100\n",
        "    bert_f1 = chemberta_bertscore_f1(preds_s, refs_s, batch_size=32)\n",
        "\n",
        "    comp = 0.5 * (bleu / 100.0) + 0.5 * bert_f1\n",
        "    return bleu, bert_f1, comp\n",
        "\n",
        "\n",
        "# Setup and evaluation utilities\n",
        "train_caps = [str(getattr(g, \"description\", \"\")) for g in train_graphs]\n",
        "val_refs   = [str(getattr(g, \"description\", \"\")) for g in val_graphs]\n",
        "\n",
        "have_gnn = (\"Z_train\" in globals()) and (Z_train is not None)\n",
        "print(\"have_gnn:\", have_gnn)\n",
        "\n",
        "# Hybrid retrieval (GNN + BOW)\n",
        "def topk_retrieve(Q_bow, K_bow, Q_gnn=None, K_gnn=None, topk=64, alpha=0.8, chunk=1024):\n",
        "    K_bow_T = K_bow.T\n",
        "    use_gnn = (Q_gnn is not None) and (K_gnn is not None) and (alpha > 1e-12)\n",
        "    if use_gnn:\n",
        "        K_gnn_T = K_gnn.T\n",
        "\n",
        "    nq = Q_bow.shape[0]\n",
        "    idx_out = np.zeros((nq, topk), dtype=np.int64)\n",
        "    sc_out  = np.zeros((nq, topk), dtype=np.float32)\n",
        "\n",
        "    for s in tqdm(range(0, nq, chunk), desc=f\"Retrieve topk={topk} alpha={alpha}\"):\n",
        "        e = min(nq, s + chunk)\n",
        "        sim = (1 - alpha) * (Q_bow[s:e] @ K_bow_T)\n",
        "        if use_gnn:\n",
        "            sim += alpha * (Q_gnn[s:e] @ K_gnn_T)\n",
        "\n",
        "        part = np.argpartition(-sim, topk, axis=1)[:, :topk]\n",
        "        part_sc = np.take_along_axis(sim, part, axis=1)\n",
        "        order = np.argsort(-part_sc, axis=1)\n",
        "        idx_out[s:e] = np.take_along_axis(part, order, axis=1)\n",
        "        sc_out[s:e]  = np.take_along_axis(part_sc, order, axis=1)\n",
        "\n",
        "    return idx_out, sc_out\n",
        "\n",
        "# TF-IDF text features\n",
        "word_tfidf = TfidfVectorizer(\n",
        "    lowercase=True, ngram_range=(1,2),\n",
        "    min_df=2, max_df=0.95,\n",
        "    max_features=250000,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "X_word = word_tfidf.fit_transform(train_caps)\n",
        "\n",
        "USE_CHAR = True\n",
        "if USE_CHAR:\n",
        "    char_tfidf = TfidfVectorizer(\n",
        "        lowercase=True, analyzer=\"char_wb\", ngram_range=(3,5),\n",
        "        min_df=2, max_df=0.95,\n",
        "        max_features=200000,\n",
        "        sublinear_tf=True\n",
        "    )\n",
        "    X_char = char_tfidf.fit_transform(train_caps)\n",
        "else:\n",
        "    X_char = None\n",
        "\n",
        "def softmax(x, beta=10.0):\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    x = x - x.max()\n",
        "    e = np.exp(beta * x)\n",
        "    return e / (e.sum() + 1e-12)\n",
        "\n",
        "def normalize01(x):\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    mn, mx = float(x.min()), float(x.max())\n",
        "    if mx - mn < 1e-12:\n",
        "        return np.zeros_like(x)\n",
        "    return (x - mn) / (mx - mn)\n",
        "\n",
        "def dedup_by_caption(ids, scores, max_keep=64):\n",
        "    best = {}\n",
        "    for j, s in zip(ids, scores):\n",
        "        cap = train_caps[int(j)]\n",
        "        s = float(s)\n",
        "        if cap not in best or s > best[cap][1]:\n",
        "            best[cap] = (int(j), s)\n",
        "    items = list(best.values())\n",
        "    items.sort(key=lambda x: -x[1])\n",
        "    items = items[:max_keep]\n",
        "    return [i for i,_ in items], [s for _,s in items]\n",
        "\n",
        "def pick_caption_tfidf(ids, scores, w_cons=0.8, w_graph=0.2, beta=10.0, max_unique=64):\n",
        "    ids, scores = dedup_by_caption(ids, scores, max_keep=max_unique)\n",
        "    if len(ids) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    ids = np.array(ids, dtype=np.int64)\n",
        "    gs  = np.array(scores, dtype=np.float32)\n",
        "    w   = softmax(gs, beta=beta)\n",
        "\n",
        "    # WORD consensus\n",
        "    Cw = X_word[ids]  # sparse (K,V)\n",
        "    Sw = (Cw @ Cw.T).toarray().astype(np.float32)  # (K,K) small dense\n",
        "    cons_w = Sw @ w\n",
        "\n",
        "    # CHAR consensus (optional)\n",
        "    if X_char is not None:\n",
        "        Cc = X_char[ids]\n",
        "        Sc = (Cc @ Cc.T).toarray().astype(np.float32)\n",
        "        cons_c = Sc @ w\n",
        "        cons = 0.5 * (cons_w + cons_c)\n",
        "    else:\n",
        "        cons = cons_w\n",
        "\n",
        "    final = w_cons * normalize01(cons) + w_graph * normalize01(gs)\n",
        "    return train_caps[int(ids[int(np.argmax(final))])]\n",
        "\n",
        "# Confidence gate for choosing captions\n",
        "def pick_with_gate(ids, scores,\n",
        "                   top1_min=0.55, gap_min=0.03,\n",
        "                   **tfidf_kwargs):\n",
        "    \"\"\"\n",
        "    ids,scores are sorted best->worst.\n",
        "    - If top1 is strong OR top1-top2 gap is large => copy top1 caption\n",
        "    - else => TF-IDF consensus among candidates\n",
        "    Tune top1_min/gap_min on val.\n",
        "    \"\"\"\n",
        "    if len(ids) == 0:\n",
        "        return \"\"\n",
        "    if len(ids) == 1:\n",
        "        return train_caps[int(ids[0])]\n",
        "\n",
        "    s1 = float(scores[0])\n",
        "    s2 = float(scores[1])\n",
        "\n",
        "    if (s1 >= top1_min) or ((s1 - s2) >= gap_min):\n",
        "        return train_caps[int(ids[0])]\n",
        "\n",
        "    return pick_caption_tfidf(ids, scores, **tfidf_kwargs)\n",
        "\n",
        "# Validation tuning\n",
        "ALPHA = 0.8 if have_gnn else 0.0\n",
        "\n",
        "# retrieve a bigger pool, then select\n",
        "POOL = 64\n",
        "v_idx, v_sc = topk_retrieve(B_val, B_train, Q_gnn=(Z_val if have_gnn else None), K_gnn=(Z_train if have_gnn else None),\n",
        "                            topk=POOL, alpha=ALPHA, chunk=1024)\n",
        "\n",
        "best = (-1, None)\n",
        "\n",
        "for top1_min in [0.50, 0.55, 0.60]:\n",
        "    for gap_min in [0.02, 0.03, 0.05]:\n",
        "        for beta in [6.0, 10.0, 14.0]:\n",
        "            preds = []\n",
        "            for i in range(len(val_graphs)):\n",
        "                preds.append(\n",
        "                    pick_with_gate(\n",
        "                        v_idx[i], v_sc[i],\n",
        "                        top1_min=top1_min, gap_min=gap_min,\n",
        "                        w_cons=0.8, w_graph=0.2, beta=beta, max_unique=64\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            bleu, bert_f1, comp = eval_bleu_chembertscore(preds, val_refs, sample_size=2000, seed=42)\n",
        "\n",
        "            print(\n",
        "                f\"VAL comp={comp:.4f} | BLEU={bleu:.3f} | ChemBERTa-F1={bert_f1:.4f} \"\n",
        "                f\"| top1_min={top1_min} gap_min={gap_min} beta={beta}\"\n",
        "            )\n",
        "\n",
        "            if comp > best[0]:\n",
        "                best = (comp, dict(top1_min=top1_min, gap_min=gap_min, beta=beta,\n",
        "                                   bleu=bleu, bert_f1=bert_f1))\n",
        "\n",
        "print(\"BEST:\", best)\n",
        "\n",
        "cfg = best[1]\n",
        "top1_min = cfg[\"top1_min\"]\n",
        "gap_min  = cfg[\"gap_min\"]\n",
        "beta     = cfg[\"beta\"]\n",
        "print(f\"Using: top1_min={top1_min}, gap_min={gap_min}, beta={beta} (BLEU={cfg['bleu']:.3f}, BERT={cfg['bert_f1']:.4f})\")\n",
        "\n",
        "\n",
        "# Predict on test set\n",
        "t_idx, t_sc = topk_retrieve(B_test, B_train, Q_gnn=(Z_test if have_gnn else None), K_gnn=(Z_train if have_gnn else None),\n",
        "                            topk=POOL, alpha=ALPHA, chunk=1024)\n",
        "\n",
        "test_preds = []\n",
        "for i in tqdm(range(len(test_graphs)), desc=\"Predict test\"):\n",
        "    test_preds.append(\n",
        "        pick_with_gate(\n",
        "            t_idx[i], t_sc[i],\n",
        "            top1_min=top1_min, gap_min=gap_min,\n",
        "            w_cons=0.8, w_graph=0.2, beta=beta, max_unique=64\n",
        "        )\n",
        "    )\n",
        "\n",
        "print(\"Example preds:\", test_preds[:3])\n",
        "\n",
        "# Write submission file\n",
        "def get_graph_id(g, fallback):\n",
        "    for k in [\"id\", \"idx\", \"graph_id\", \"mol_id\"]:\n",
        "        if hasattr(g, k):\n",
        "            v = getattr(g, k)\n",
        "            if isinstance(v, (int, np.integer)):\n",
        "                return int(v)\n",
        "            if isinstance(v, str) and v.strip():\n",
        "                return v\n",
        "    return fallback\n",
        "\n",
        "sample_path = None\n",
        "for root, _, files in os.walk(comp_path):\n",
        "    for f in files:\n",
        "        fn = f.lower()\n",
        "        if fn.endswith(\".csv\") and (\"sample\" in fn) and (\"submission\" in fn):\n",
        "            sample_path = os.path.join(root, f)\n",
        "            break\n",
        "    if sample_path:\n",
        "        break\n",
        "\n",
        "if sample_path is not None:\n",
        "    sample = pd.read_csv(sample_path)\n",
        "    target_col = sample.columns[1] if len(sample.columns) > 1 else \"description\"\n",
        "    sub = sample.copy()\n",
        "    sub[target_col] = test_preds\n",
        "else:\n",
        "    ids = [get_graph_id(g, i) for i, g in enumerate(test_graphs)]\n",
        "    sub = pd.DataFrame({\"id\": ids, \"description\": test_preds})\n",
        "\n",
        "sub.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ Wrote submission.csv\")\n",
        "display(sub.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPjv0KEkO4_E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012abfe890ab47e28148f78bc9bfbe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21c34265184a4677936125e8831a9348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2f60acb947204b1abe43e3cf15ad585a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ef261d493b44d8b0c33fb9ace2b651": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45fdc78a3ef243a79f23ba8887daf092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ef4dd97d46224613a348ebb812f25b49",
            "placeholder": "​",
            "style": "IPY_MODEL_012abfe890ab47e28148f78bc9bfbe8b",
            "value": ""
          }
        },
        "4dd8115b782745cc95a149ab9b33e57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f60acb947204b1abe43e3cf15ad585a",
            "placeholder": "​",
            "style": "IPY_MODEL_f181094afd1e4b90afce285a094242d4",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "509bf928bc424bb2894c49630bf0dbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d35dc7ec5834548be157f8a56133c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d784dd987d940adbbb7ca32181e145d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a495d223f946ff8230cc97a84df861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991af4b385474cee845d49dd86a9b6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a348fd4d5455405eba966d551b30c6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_991af4b385474cee845d49dd86a9b6d4",
            "placeholder": "​",
            "style": "IPY_MODEL_509bf928bc424bb2894c49630bf0dbc2",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "b8b2cd3f0c1a4329b2d76b88c2e5bfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a348fd4d5455405eba966d551b30c6bb"
            ],
            "layout": "IPY_MODEL_f734b85eb5a04a03af1d5b5d643cbd99"
          }
        },
        "c4aba02db5de43d3a98e7e602b107d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c5e0db96fe7f40db8b0ff9f9efc0316d",
            "placeholder": "​",
            "style": "IPY_MODEL_97a495d223f946ff8230cc97a84df861",
            "value": "christellehorkos"
          }
        },
        "c5e0db96fe7f40db8b0ff9f9efc0316d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf74fc6b5e341bdb7e910e57d33f6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e35513690b674c6e9a076b1921f374cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee3ab68a6b9451b9327745c701f69b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5d784dd987d940adbbb7ca32181e145d",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "ea3a6d849cb24ebb88b852ca97bfbab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ef261d493b44d8b0c33fb9ace2b651",
            "placeholder": "​",
            "style": "IPY_MODEL_5d35dc7ec5834548be157f8a56133c3f",
            "value": "Connecting..."
          }
        },
        "eed8a8ae65604eb3bde5b1e973f4474e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ddf74fc6b5e341bdb7e910e57d33f6ef",
            "style": "IPY_MODEL_21c34265184a4677936125e8831a9348",
            "tooltip": ""
          }
        },
        "ef4dd97d46224613a348ebb812f25b49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f181094afd1e4b90afce285a094242d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f734b85eb5a04a03af1d5b5d643cbd99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "fee3ab68a6b9451b9327745c701f69b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
